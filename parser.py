print('Start parsing process.')

import bs4 
import pandas as pd
import requests
from selenium import webdriver
import re
import pandas as pd
import gspread
from df2gspread import df2gspread as d2g
import datetime
import gspread_dataframe as gd
import twitter
import tweepy
from twython import Twython
import gspread
from oauth2client.service_account import ServiceAccountCredentials

## parsing initial chunk of Tweets

consumer_key="KPlm7I1m5I3L0CsjMoIRPoion"
consumer_secret='JXuQr0LuPGFrm6yX3BaBYqjoEpz3qu8p1ob8OfA6gkAXgJukdP'
access_token_key='2416209656-LPUzW7OzvWK7DYJGHRoVsc115COg05VZxYGnP4K'
access_token_secret='IKYPuIKeZoTiFykkFfWisBkxIZi0cEUVGi94OkREOLZon'

tweets = Twython(consumer_key, consumer_secret)

keywords = ['幼幼','幼女','处女','#幼幼','#幼女','#处女']

dict_ = {'user':[], 'user_id':[], 'user_desc':[], 'user_location':[], 
         'geo':[], 'date':[], 'text':[], 'text':[], 'favorite_count':[], 
         'hashtags':[], 'retweets_user':[], 'retweets_text':[]}

for keyword in keywords:
    try:
        print("Parsing tweets for: ", keyword)
        query = {'q': keyword,
                'count': 1000,
                 'lang': 'zh'}

        for status in tweets.search(**query)['statuses']:
            dict_['user'].append(status['user']['screen_name'])
            dict_['user_id'].append(status['user']['id'])
            dict_['user_desc'].append(status['user']['description'])
            dict_['user_location'].append(status['user']['location'])
            dict_['geo'].append(status['coordinates'])
            dict_['date'].append(status['created_at'])
            dict_['text'].append(status['text'])
            if 'media' in status.keys():
                dict_['media'].append(status['media']['media_url'])
            else: 
                dict_['favorite_count'].append("")
            if 'hashtags' in status.keys():
                dict_['hashtags'].append([x['text'] for x in status['hashtags'] if len(status['hashtags']) > 0])
            else:
                dict_['hashtags'].append("")
            if 'retweeted_status' in status.keys():
                dict_['retweets_user'].append(status['retweeted_status']['user']['id'])
                dict_['retweets_text'].append(status['retweeted_status']['text'])
            else:
                dict_['retweets_user'].append("")
                dict_['retweets_text'].append("")
    except:
        print(keyword, 'GET HTTP ERROR') 
        print('-------------------------------------------------------------')
        print('-------------------------------------------------------------')


twitter_extract = pd.DataFrame(dict_)

print('Complete parsing process.')

#twitter_extract.to_csv(r'twitter_extract.csv')
twitter_extract_old = pd.read_csv(r'twitter_extract.csv', encoding='utf_8_sig').drop(columns=['Unnamed: 0']).fillna(0)
twitter_extract_old = twitter_extract_old.append(twitter_extract,ignore_index = True).fillna(0)
twitter_extract_old.to_csv(r"twitter_extract.csv", encoding='utf_8_sig')

twitter_extract_left = twitter_extract_old.groupby(['user', 'text']).size().reset_index(name='Freq')
twitter_extract_full = pd.merge(twitter_extract_left,twitter_extract_old,on = ['text','user'], how = 'left')

twitter_extract_old['favorite_count'] = twitter_extract_old['favorite_count'].apply(lambda x: 0 if x == '' else x)
twitter_extract_full = twitter_extract_old.groupby(['user', 'text']).agg({'user_id':'first', 'user_desc':'first', 
                                                                          'user_location':'first', 'geo':'first',
                                                                          'date':'first', 'favorite_count':'sum', 
                                                                          'hashtags':'first', 'retweets_user':'first',
                                                                          'retweets_text':'first'}).reset_index()

import gspread
from oauth2client.service_account import ServiceAccountCredentials

scope = ['https://spreadsheets.google.com/feeds',
         'https://www.googleapis.com/auth/drive']

credentials = ServiceAccountCredentials.from_json_keyfile_name('driveapi-266014-212bb7e59803.json', scope)

gc = gspread.authorize(credentials)

spreadsheet_key = '1VLW_AViqW__kwbfQzCRMEz00Fly1OYadRGeCGye8EwY'
wks_name = 'Master'
d2g.upload(twitter_extract_full, spreadsheet_key, wks_name, credentials=credentials, row_names=True)

print('Uploaded to Google Drive.')